{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import category_encoders\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('future.no_silent_downcasting', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that correct virtual env is being used\n",
    "#print(sys.executable)\n",
    "print(sys.version)\n",
    "\n",
    "# list all installed modules\n",
    "#%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns that don't contain any important information, since all entries have the same entry\n",
    "def remove_columns_with_a_single_value(original_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    return original_dataframe[[column for column in original_dataframe.columns if len(original_dataframe[column].unique()) > 1]]\n",
    "\n",
    "def encode_time(original_dataframe: pd.DataFrame, columns_to_encode: list[str], period: int) -> pd.DataFrame:\n",
    "    for column in columns_to_encode:\n",
    "        original_dataframe[column] = original_dataframe[column].astype('float64')\n",
    "        original_dataframe[column + '_sin'] = np.sin(2 * np.pi * original_dataframe[column] / period)\n",
    "        original_dataframe[column + '_cos'] = np.cos(2 * np.pi * original_dataframe[column] / period)\n",
    "    original_dataframe = original_dataframe.drop(columns=columns_to_encode)\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_time_utc(original_dataframe: pd.DataFrame, column_to_encode: str, pattern: str) -> pd.DataFrame:\n",
    "    timestamps = []\n",
    "    for i in range(len(original_dataframe)):\n",
    "        time_stamp = original_dataframe.loc[i, column_to_encode]\n",
    "        if time_stamp.__contains__(\".\"):\n",
    "            pattern = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "        else: \n",
    "            pattern = '%Y-%m-%dT%H:%M:%SZ'\n",
    "        time_stamp = datetime.strptime(original_dataframe.loc[i, column_to_encode], pattern)\n",
    "        timestamps.append(time_stamp.timestamp())\n",
    "\n",
    "    original_dataframe[column_to_encode] = timestamps\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_weather_time_utc(original_dataframe: pd.DataFrame, column_to_encode: str, pattern: str) -> pd.DataFrame:\n",
    "    timestamps = []\n",
    "    for i in range(len(original_dataframe)):\n",
    "        time_stamp = original_dataframe.loc[i, column_to_encode]\n",
    "        time_stamp = datetime.strptime(original_dataframe.loc[i, column_to_encode], pattern)\n",
    "        timestamps.append(time_stamp.timestamp())\n",
    "\n",
    "    original_dataframe[column_to_encode] = timestamps\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_time_local(original_dataframe: pd.DataFrame, column_to_encode: str, pattern: str) -> pd.DataFrame:\n",
    "    timestamps = []\n",
    "    for i in range(len(original_dataframe)):\n",
    "        time_stamp = original_dataframe.loc[i, column_to_encode]\n",
    "        if time_stamp.__contains__(\".\"):\n",
    "            pattern = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "        else: \n",
    "            pattern = '%Y-%m-%dT%H:%M:%S'\n",
    "        time_stamp = datetime.strptime(original_dataframe.loc[i, column_to_encode], pattern)\n",
    "        timestamps.append(time_stamp.timestamp())\n",
    "\n",
    "    original_dataframe[column_to_encode] = timestamps\n",
    "    return original_dataframe\n",
    "\n",
    "\n",
    "def number_of_unique_values_per_column(dataframe: pd.DataFrame) -> list[(str, int)]:\n",
    "    return [(column, dataframe[column].nunique()) for column in dataframe.columns]\n",
    "\n",
    "def onehot_encode_column(original_dataframe: pd.DataFrame, column_to_encode: str) -> pd.DataFrame:\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded_column = encoder.fit_transform(original_dataframe[[column_to_encode]])\n",
    "    encoded_column_dataframe = pd.DataFrame(encoded_column.toarray(), columns=encoder.get_feature_names_out([column_to_encode]))\n",
    "    original_dataframe = pd.concat([original_dataframe, encoded_column_dataframe], axis=1)\n",
    "    if column_to_encode != \"session_id\":\n",
    "        original_dataframe = original_dataframe.drop(columns=[column_to_encode])\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_classification(original_dataframe: pd.DataFrame, column_to_encode: str) -> pd.DataFrame:\n",
    "    label_encoder = LabelEncoder()\n",
    "    original_dataframe[column_to_encode] = label_encoder.fit_transform(original_dataframe[column_to_encode])\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_boolean(original_dataframe: pd.DataFrame, columns_to_encode: list[str]) -> pd.DataFrame:\n",
    "    for index in range(0, len(columns_to_encode)):\n",
    "        original_dataframe[columns_to_encode[index]] = original_dataframe[columns_to_encode[index]].astype('int')\n",
    "    return original_dataframe\n",
    "\n",
    "def category_encode_column(original_dataframe: pd.DataFrame, column_to_encode: str) -> pd.DataFrame:\n",
    "    binary_encoder = category_encoders.BinaryEncoder(cols=column_to_encode)\n",
    "    original_dataframe = binary_encoder.fit_transform(original_dataframe)\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_str_to_enum(original_dataframe: pd.DataFrame, column_to_encode: str) -> pd.DataFrame:\n",
    "    encoding_dict = dict()\n",
    "    encoded_value = 0\n",
    "    for index in range(len(original_dataframe)):\n",
    "        value = original_dataframe.iloc[index][column_to_encode]\n",
    "        if value in encoding_dict:\n",
    "            original_dataframe.at[index, column_to_encode] = encoding_dict[value]\n",
    "        else: \n",
    "            encoding_dict[value] = encoded_value\n",
    "            original_dataframe.at[index, column_to_encode] = encoded_value\n",
    "            encoded_value += 1\n",
    "    return original_dataframe\n",
    "\n",
    "def move_column_to_the_front(original_dataframe: pd.DataFrame, column_to_move: str) -> pd.DataFrame:\n",
    "    first_column = original_dataframe.pop(column_to_move)\n",
    "    original_dataframe.insert(0, column_to_move, first_column)\n",
    "    return original_dataframe\n",
    "\n",
    "def get_weather_data(original_dataframe: pd.DataFrame, column_to_encode: str, json_subarray_name: str) -> pd.DataFrame:\n",
    "    weather_data_list = []\n",
    "    \n",
    "    for _, row in original_dataframe.iterrows():\n",
    "        weather_day_id = row[column_to_encode]\n",
    "        weather_day_data = parsed_json[json_subarray_name][str(weather_day_id)]\n",
    "        weather_day_data = {f\"{column_to_encode} {k}\": v for k, v in weather_day_data.items() if k != 'id'}\n",
    "        weather_data_list.append(weather_day_data)\n",
    "    weather_data_df = pd.DataFrame(weather_data_list)\n",
    "    weather_data_df = remove_columns_with_a_single_value(weather_data_df)\n",
    "    \n",
    "    if column_to_encode == \"weather_day_id\":\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} sun_set', \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} sun_rise', \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} created_at', \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} calculated_at', \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    elif column_to_encode == \"weather_hour_id\":\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} created_at', \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} calculated_at', \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        weather_data_df = encode_weather_time_utc(weather_data_df, f'{column_to_encode} forecast_time', \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    original_dataframe = pd.concat([original_dataframe, weather_data_df], axis=1)\n",
    "    return original_dataframe\n",
    "\n",
    "def get_content_map(original_dataframe: pd.DataFrame, column_to_encode: str, json_subarray_name: str) -> pd.DataFrame:\n",
    "    content_data_list = []\n",
    "    \n",
    "    for _, row in original_dataframe.iterrows():\n",
    "        content_id = row[column_to_encode]\n",
    "        content_id_data = parsed_json[json_subarray_name][str(content_id)]\n",
    "        content_id_data = {f\"{column_to_encode} {k}\": v for k, v in content_id_data.items()}\n",
    "        content_data_list.append(content_id_data)\n",
    "    content_data_df = pd.DataFrame(content_data_list)\n",
    "    original_dataframe = pd.concat([original_dataframe, content_data_df], axis=1)\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_date(original_dataframe: pd.DataFrame, column_to_encode: str) -> pd.DataFrame:\n",
    "    for _, row in original_dataframe.iterrows():\n",
    "        date_object = datetime.strptime(row[column_to_encode], \"%Y-%m-%d\")\n",
    "        original_dataframe[column_to_encode] = date_object.toordinal()\n",
    "    return original_dataframe\n",
    "\n",
    "def encode_weather_enums(original_dataframe: pd.DataFrame, json_subarray_name: str, json_key: str) -> pd.DataFrame:\n",
    "    weather_day_data = parsed_json[json_subarray_name][json_key]\n",
    "    for index in range(0, len(original_dataframe)):\n",
    "        for key, value in weather_day_data.items():\n",
    "            if original_dataframe.loc[index, f'weather_hour_id {json_key}'] == value:\n",
    "                original_dataframe.loc[index, f'weather_hour_id {json_key}'] = key     \n",
    "    return original_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['device_country_iso2'], dtype='object')\n",
      "Index(['device_country_iso2'], dtype='object')\n",
      "0\n",
      "337\n",
      "2790\n",
      "[('prev_content_id', 105), ('prev_prev_content_id', 105), ('session_id', 76), ('device_id', 41), ('content_id', 104), ('time_utc', 404), ('event_type_0', 2), ('event_type_1', 2), ('event_type_2', 2), ('time_local', 404), ('device_platform_0', 2), ('device_platform_1', 2), ('device_platform_2', 2), ('device_width_px', 18), ('device_height_px', 26), ('device_country_iso2_0', 2), ('device_country_iso2_1', 2), ('device_country_iso2_2', 2), ('device_language_iso2_0', 2), ('device_language_iso2_1', 2), ('device_language_iso2_2', 2), ('time_hod_sin', 19), ('time_hod_cos', 18), ('time_dow_sin', 7), ('time_dow_cos', 7), ('weather_day_id sun_set', 35), ('weather_day_id sun_rise', 35), ('weather_day_id created_at', 35), ('weather_day_id moon_phase_0', 2), ('weather_day_id moon_phase_1', 2), ('weather_day_id moon_phase_2', 2), ('weather_day_id moon_phase_3', 2), ('weather_day_id sunshine_h', 26), ('weather_day_id temp_max_c', 32), ('weather_day_id temp_min_c', 32), ('weather_day_id calculated_at', 35), ('weather_day_id forecast_date', 1), ('weather_day_id prec_prob_pct', 7), ('weather_day_id prec_rain_mm_h', 6), ('weather_day_id prec_snow_mm_h', 7), ('weather_day_id wind_direction_0', 2), ('weather_day_id wind_direction_1', 2), ('weather_day_id wind_direction_2', 2), ('weather_day_id wind_speed_kmh', 8), ('weather_day_id prec_total_mm_h', 14), ('weather_day_id temp_felt_max_c', 32), ('weather_day_id temp_felt_min_c', 32), ('weather_day_id humidity_mean_pct', 18), ('weather_day_id wind_speed_max_kmh', 4), ('weather_day_id cloud_cover_max_pct', 31), ('weather_day_id cloud_cover_min_pct', 19), ('weather_day_id cloud_cover_mean_pct', 26), ('weather_hour_id temp_c', 53), ('weather_hour_id created_at', 51), ('weather_hour_id sunshine_h', 34), ('weather_hour_id temp_felt_c', 50), ('weather_hour_id humidity_pct', 36), ('weather_hour_id calculated_at', 51), ('weather_hour_id forecast_time', 67), ('weather_hour_id prec_rain_mm_h', 13), ('weather_hour_id prec_snow_mm_h', 4), ('weather_hour_id wind_direction_0', 2), ('weather_hour_id wind_direction_1', 2), ('weather_hour_id wind_direction_2', 2), ('weather_hour_id wind_direction_3', 2), ('weather_hour_id wind_speed_kmh', 11), ('weather_hour_id cloud_cover_pct', 39), ('weather_hour_id prec_total_mm_h', 14), ('weather_hour_id forecast_distance_h', 6), ('content_portal_0', 1), ('device_online_1', 1), ('device_class_0', 2), ('device_class_1', 2), ('device_class_2', 2), ('device_orientation_0', 2), ('device_orientation_1', 2), ('oha_language_iso2_0', 2), ('oha_language_iso2_1', 2), ('oha_layout_0', 2), ('oha_layout_1', 2), ('weather_hour_id thunderstorm_prob_0', 2), ('weather_hour_id thunderstorm_prob_1', 2), ('weather_day_id thunderstorm_prob_0', 2), ('weather_day_id thunderstorm_prob_1', 2)]\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "# read json data\n",
    "with open(\"datasets\\\\transfer\\\\larger_dataset.json\") as file:\n",
    "    parsed_json = json.load(file)\n",
    "\n",
    "# build dataframe \n",
    "total_amount_of_rows = 0\n",
    "all_sessions = pd.DataFrame()\n",
    "for i in pd.json_normalize(parsed_json['traces']):\n",
    "    total_amount_of_rows += len(pd.json_normalize(parsed_json['traces'][i]))\n",
    "    single_session = pd.json_normalize(parsed_json['traces'][i])\n",
    "    single_session_filtered = single_session.dropna(how='all', axis=1)\n",
    "    #dropped_columns = set(single_session.columns) - set(single_session_filtered.columns)\n",
    "    #print(\"Dropped columns:\", dropped_columns)\n",
    "    all_sessions = pd.concat([all_sessions, single_session_filtered], ignore_index=True)\n",
    "\n",
    "all_sessions = all_sessions.drop(columns=['weather_future_day_id', 'weather_future_hour_id'])\n",
    "all_sessions = all_sessions.drop(columns=['event_data.for_date', 'event_data.for_date_days_in_future'])\n",
    "\n",
    "all_sessions = all_sessions.infer_objects(copy=False)\n",
    "null_columns = all_sessions.columns[all_sessions.isnull().any()]\n",
    "print(null_columns)\n",
    "\n",
    "null_columns = all_sessions.columns[all_sessions.isnull().any()]\n",
    "print(null_columns)\n",
    "for column in null_columns:\n",
    "    all_sessions[column] = all_sessions[column].fillna(all_sessions[column].mode()[0])\n",
    "\n",
    "null_columns = all_sessions.columns[all_sessions.isnull().any()]\n",
    "\n",
    "all_sessions = encode_time(all_sessions, ['time_hod'], 24)\n",
    "all_sessions = encode_time(all_sessions, ['time_dow'], 7)\n",
    "all_sessions = encode_time_local(all_sessions, 'time_local', '%Y-%m-%dT%H:%M:%S.%f')\n",
    "all_sessions = encode_time_utc(all_sessions, 'time_utc', '%Y-%m-%dT%H:%M:%SZ')\n",
    "all_sessions = encode_boolean(all_sessions, ['device_online'])\n",
    "all_sessions = encode_str_to_enum(all_sessions, 'content_portal')\n",
    "\n",
    "# get more in-depth weather data\n",
    "all_sessions = get_weather_data(all_sessions, 'weather_day_id', 'weather_day_map')\n",
    "all_sessions = get_weather_data(all_sessions, 'weather_hour_id', 'weather_hour_map')\n",
    "\n",
    "# too many null values\n",
    "all_sessions = all_sessions.drop(columns=['weather_day_id moon_set', 'weather_day_id moon_rise'])\n",
    "all_sessions = all_sessions.drop(columns=['weather_day_id', 'weather_hour_id'])\n",
    "\n",
    "# encode non int values from the weather data\n",
    "all_sessions = encode_date(all_sessions, 'weather_day_id forecast_date')\n",
    "all_sessions = encode_weather_enums(all_sessions, 'weather_enums', 'wind_direction')\n",
    "all_sessions = encode_weather_enums(all_sessions, 'weather_enums', 'thunderstorm_prob')\n",
    "\n",
    "ohe_features = ['content_portal', 'device_online', 'device_class', 'device_orientation', 'oha_language_iso2', 'oha_layout', 'weather_hour_id thunderstorm_prob', 'weather_day_id thunderstorm_prob']\n",
    "numerical_features = ['time_utc', 'time_local', 'device_height_px', 'device_width_px']\n",
    "numerical_features2 = ['weather_day_id sun_set', 'weather_day_id sun_rise', 'weather_day_id created_at', 'weather_day_id sunshine_h', 'weather_day_id temp_max_c', 'weather_day_id temp_min_c', 'weather_day_id calculated_at', 'weather_day_id forecast_date', 'weather_day_id prec_prob_pct', 'weather_day_id prec_rain_mm_h', 'weather_day_id prec_snow_mm_h', 'weather_day_id wind_speed_kmh', 'weather_day_id prec_total_mm_h', 'weather_day_id temp_felt_max_c', 'weather_day_id temp_felt_min_c', 'weather_day_id humidity_mean_pct', 'weather_day_id wind_speed_max_kmh', 'weather_day_id cloud_cover_max_pct', 'weather_day_id cloud_cover_min_pct', 'weather_day_id cloud_cover_mean_pct', 'weather_hour_id temp_c', 'weather_hour_id created_at', 'weather_hour_id sunshine_h', 'weather_hour_id temp_felt_c', 'weather_hour_id humidity_pct', 'weather_hour_id calculated_at', 'weather_hour_id forecast_time', 'weather_hour_id prec_rain_mm_h', 'weather_hour_id prec_snow_mm_h', 'weather_hour_id wind_speed_kmh', 'weather_hour_id cloud_cover_pct', 'weather_hour_id prec_total_mm_h', 'weather_hour_id forecast_distance_h']\n",
    "\n",
    "binary_features = ['device_country_iso2', 'device_language_iso2', 'event_type', 'device_platform', 'weather_hour_id wind_direction', 'weather_day_id wind_direction', 'weather_day_id moon_phase']\n",
    "embedded_features = ['content_id', 'device_id', 'session_id']\n",
    "\n",
    "for column in embedded_features:\n",
    "    all_sessions = encode_classification(all_sessions, column)\n",
    "    all_sessions = move_column_to_the_front(all_sessions, column)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for column in numerical_features:\n",
    "    all_sessions[column] = scaler.fit_transform(np.array(all_sessions[column]).reshape(-1, 1))\n",
    "for column in numerical_features2:\n",
    "    all_sessions[column] = scaler.fit_transform(np.array(all_sessions[column]).reshape(-1, 1))\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "for column in ohe_features:\n",
    "    all_sessions = onehot_encode_column(all_sessions, column)\n",
    "\n",
    "for column in binary_features:\n",
    "    #all_sessions = onehot_encode_column(all_sessions, column)\n",
    "    all_sessions = category_encode_column(all_sessions, column)\n",
    "\n",
    "print(all_sessions.isnull().sum().sum())\n",
    "\n",
    "all_sessions[f'prev_content_id'] = all_sessions['content_id'].shift(1)\n",
    "all_sessions[f'prev_prev_content_id'] = all_sessions['content_id'].shift(2)\n",
    "\n",
    "all_sessions = move_column_to_the_front(all_sessions, 'prev_prev_content_id')\n",
    "all_sessions = move_column_to_the_front(all_sessions, 'prev_content_id')\n",
    "all_sessions.fillna({'prev_content_id': 104}, inplace=True)\n",
    "all_sessions.fillna({'prev_prev_content_id': 104}, inplace=True)\n",
    "\n",
    "'''\n",
    "print(all_sessions.iloc[0])\n",
    "all_sessions.fillna({'prev_prev_event': 39}, inplace=True)\n",
    "all_sessions = move_column_to_the_front(all_sessions, 'prev_prev_event')\n",
    "'''\n",
    "\n",
    "unique_classifications = all_sessions['content_id'].nunique()\n",
    "\n",
    "# build features vectors\n",
    "feature_vectors = []\n",
    "for i in range(0, len(all_sessions)):\n",
    "    if i < len(all_sessions) - 1:\n",
    "        if all_sessions.iloc[i]['session_id'] == all_sessions.iloc[i+1]['session_id']:\n",
    "            feature_vector = (all_sessions.iloc[i], all_sessions.iloc[i+1]['content_id']) \n",
    "            feature_vectors.append(feature_vector)\n",
    "\n",
    "# shuffle dataset\n",
    "#random.shuffle(feature_vectors)\n",
    "\n",
    "# build train / test sets\n",
    "input_features = []\n",
    "classification_labels = []\n",
    "\n",
    "for input_feature, classification in feature_vectors:\n",
    "    input_features.append(input_feature)\n",
    "    classification_labels.append(classification)\n",
    "\n",
    "input_features_array = np.array(input_features)\n",
    "classification_labels_array = np.array(classification_labels)\n",
    "\n",
    "print(len(input_features_array))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "input_resampled, classification_resampled = ros.fit_resample(input_features_array, classification_labels_array)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_resampled, classification_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape[0] + X_test.shape[0])\n",
    "print(number_of_unique_values_per_column(all_sessions))\n",
    "print(unique_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2232, 84)\n",
      "(2232, 79)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train_prev_event, X_train = X_train[:, :1], X_train[:, 1:]\n",
    "X_train_prev_prev_event, X_train = X_train[:, :1], X_train[:, 1:]\n",
    "X_train_session_id, X_train = X_train[:, :1], X_train[:, 1:]\n",
    "X_train_device_id, X_train = X_train[:, :1], X_train[:, 1:]\n",
    "X_train_content_id, X_train = X_train[:, :1], X_train[:, 1:]\n",
    "\n",
    "X_train_prev_event_input_dim = len(set(X_train_prev_event.flatten()))\n",
    "X_train_prev_prev_event_input_dim = len(set(X_train_prev_event.flatten()))\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test_prev_event, X_test = X_test[:, :1], X_test[:, 1:]\n",
    "X_test_prev_prev_event, X_test = X_test[:, :1], X_test[:, 1:]\n",
    "X_test_session_id, X_test = X_test[:, :1], X_test[:, 1:]\n",
    "X_test_device_id, X_test = X_test[:, :1], X_test[:, 1:]\n",
    "X_test_content_id, X_test = X_test[:, :1], X_test[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 18m 14s]\n",
      "val_accuracy: 0.5645041267077128\n",
      "\n",
      "Best val_accuracy So Far: 0.8970917463302612\n",
      "Total elapsed time: 12h 54m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabio\\miniconda3\\envs\\BA\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 32 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9207 - loss: 4.1239\n",
      "[test loss, test accuracy]: [4.26212739944458, 0.899328887462616]\n",
      "Reloading Tuner from trained_models\\DI_9\\tuner0.json\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9094 - loss: 4.1005\n",
      "[test loss, test accuracy]: [4.064127445220947, 0.9082773923873901]\n",
      "Reloading Tuner from trained_models\\DI_9\\tuner0.json\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9438 - loss: 3.9304\n",
      "[test loss, test accuracy]: [3.9562718868255615, 0.9237667918205261]\n",
      "Reloading Tuner from trained_models\\DI_9\\tuner0.json\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9303 - loss: 3.9706\n",
      "[test loss, test accuracy]: [3.9952571392059326, 0.9237667918205261]\n",
      "Reloading Tuner from trained_models\\DI_9\\tuner0.json\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9001 - loss: 4.0132\n",
      "[test loss, test accuracy]: [4.052516460418701, 0.8856502175331116]\n",
      "Average validation accuracy across all folds: 0.9081580162048339\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabio\\miniconda3\\envs\\BA\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 32 variables whereas the saved optimizer has 2 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.8128 - loss: 7.8420 - val_accuracy: 0.8658 - val_loss: 4.9667\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8643 - loss: 4.5161 - val_accuracy: 0.8568 - val_loss: 4.4842\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8710 - loss: 4.3052 - val_accuracy: 0.8591 - val_loss: 4.8803\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8709 - loss: 4.4991 - val_accuracy: 0.8591 - val_loss: 5.3552\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8646 - loss: 4.9709 - val_accuracy: 0.8389 - val_loss: 5.5139\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8704 - loss: 5.1409 - val_accuracy: 0.8501 - val_loss: 5.1927\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8521 - loss: 5.2905 - val_accuracy: 0.8971 - val_loss: 4.7906\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8727 - loss: 5.0648 - val_accuracy: 0.8792 - val_loss: 4.7918\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8605 - loss: 4.8081 - val_accuracy: 0.8613 - val_loss: 5.4640\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8481 - loss: 4.8090 - val_accuracy: 0.8881 - val_loss: 4.4563\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8651 - loss: 4.5233 - val_accuracy: 0.8322 - val_loss: 5.0141\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8529 - loss: 4.7315 - val_accuracy: 0.8568 - val_loss: 4.9243\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8649 - loss: 4.7189 - val_accuracy: 0.8881 - val_loss: 4.0655\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8282 - loss: 5.1955 - val_accuracy: 0.8814 - val_loss: 5.0379\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8454 - loss: 4.8479 - val_accuracy: 0.8993 - val_loss: 3.9778\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8594 - loss: 4.2362 - val_accuracy: 0.8881 - val_loss: 4.0203\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8569 - loss: 4.2485 - val_accuracy: 0.8926 - val_loss: 3.8523\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8622 - loss: 4.1619 - val_accuracy: 0.8926 - val_loss: 4.0596\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8509 - loss: 4.2228 - val_accuracy: 0.8188 - val_loss: 4.7113\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8642 - loss: 3.9800 - val_accuracy: 0.8412 - val_loss: 3.6375\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8568 - loss: 3.6784 - val_accuracy: 0.8971 - val_loss: 3.8035\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8653 - loss: 3.8823 - val_accuracy: 0.8725 - val_loss: 3.7999\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8672 - loss: 3.7607 - val_accuracy: 0.8859 - val_loss: 3.4182\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8592 - loss: 3.6473 - val_accuracy: 0.8546 - val_loss: 5.1663\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8608 - loss: 4.1398 - val_accuracy: 0.8680 - val_loss: 3.5533\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8834 - loss: 3.4972 - val_accuracy: 0.8568 - val_loss: 3.9926\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8664 - loss: 3.5847 - val_accuracy: 0.8792 - val_loss: 3.6525\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8770 - loss: 3.3258 - val_accuracy: 0.8434 - val_loss: 3.8831\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8624 - loss: 3.5469 - val_accuracy: 0.9083 - val_loss: 3.2652\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.8753 - loss: 3.2923 - val_accuracy: 0.8523 - val_loss: 3.0483\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8692 - loss: 3.0323 - val_accuracy: 0.8613 - val_loss: 4.1832\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8742 - loss: 3.3542 - val_accuracy: 0.8837 - val_loss: 2.8118\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8795 - loss: 2.8942 - val_accuracy: 0.8859 - val_loss: 3.1847\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8793 - loss: 2.9852 - val_accuracy: 0.8367 - val_loss: 3.0486\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8672 - loss: 3.4034 - val_accuracy: 0.8859 - val_loss: 3.1211\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8505 - loss: 3.5664 - val_accuracy: 0.8635 - val_loss: 3.9687\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8579 - loss: 3.6762 - val_accuracy: 0.8792 - val_loss: 2.7139\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8781 - loss: 3.0792 - val_accuracy: 0.9038 - val_loss: 3.3931\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8660 - loss: 3.3530 - val_accuracy: 0.8747 - val_loss: 3.4523\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8721 - loss: 3.1755 - val_accuracy: 0.8770 - val_loss: 3.3958\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8728 - loss: 3.3638 - val_accuracy: 0.7696 - val_loss: 3.8413\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8603 - loss: 3.3733 - val_accuracy: 0.8345 - val_loss: 5.2323\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8813 - loss: 3.7587 - val_accuracy: 0.8747 - val_loss: 3.5951\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8815 - loss: 3.3360 - val_accuracy: 0.8479 - val_loss: 4.1514\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8720 - loss: 3.7036 - val_accuracy: 0.8837 - val_loss: 3.4907\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8862 - loss: 3.2356 - val_accuracy: 0.8770 - val_loss: 3.3573\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8929 - loss: 3.1691 - val_accuracy: 0.8613 - val_loss: 4.0534\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8700 - loss: 3.3613 - val_accuracy: 0.9016 - val_loss: 3.6591\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8648 - loss: 3.6777 - val_accuracy: 0.8702 - val_loss: 2.8410\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8600 - loss: 3.4768 - val_accuracy: 0.8300 - val_loss: 3.2078\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8595 - loss: 3.0135\n",
      "Test loss: 3.130251169204712, Test accuracy: 0.8494623899459839\n",
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8745 - loss: 3.0793 - val_accuracy: 0.8971 - val_loss: 2.7590\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8842 - loss: 2.8092 - val_accuracy: 0.8814 - val_loss: 3.8293\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8853 - loss: 3.0394 - val_accuracy: 0.8971 - val_loss: 2.9983\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8535 - loss: 3.3744 - val_accuracy: 0.8904 - val_loss: 2.9263\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8824 - loss: 3.0346 - val_accuracy: 0.9060 - val_loss: 3.4978\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8609 - loss: 3.4235 - val_accuracy: 0.8658 - val_loss: 4.0417\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8647 - loss: 3.7570 - val_accuracy: 0.8792 - val_loss: 3.0524\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.8573 - loss: 3.2043 - val_accuracy: 0.8523 - val_loss: 4.0159\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.8836 - loss: 3.2834 - val_accuracy: 0.8635 - val_loss: 3.6299\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8602 - loss: 3.9037 - val_accuracy: 0.8792 - val_loss: 3.8484\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.8726 - loss: 3.2492 - val_accuracy: 0.9105 - val_loss: 2.8261\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8970 - loss: 2.5919 - val_accuracy: 0.8837 - val_loss: 3.0561\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8656 - loss: 3.4663 - val_accuracy: 0.8881 - val_loss: 2.7414\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8735 - loss: 3.0184 - val_accuracy: 0.8814 - val_loss: 3.2157\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8724 - loss: 2.9187 - val_accuracy: 0.8233 - val_loss: 2.8880\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8859 - loss: 2.7231 - val_accuracy: 0.8993 - val_loss: 3.6366\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8564 - loss: 3.5942 - val_accuracy: 0.8904 - val_loss: 3.2230\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8594 - loss: 3.1146 - val_accuracy: 0.8881 - val_loss: 3.1173\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8700 - loss: 3.5539 - val_accuracy: 0.8389 - val_loss: 3.8485\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8592 - loss: 3.7452 - val_accuracy: 0.8322 - val_loss: 2.9392\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.8914 - loss: 2.7865 - val_accuracy: 0.9239 - val_loss: 2.8815\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8739 - loss: 2.9485 - val_accuracy: 0.8837 - val_loss: 3.2448\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8668 - loss: 3.1217 - val_accuracy: 0.9128 - val_loss: 3.6078\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8834 - loss: 2.9957 - val_accuracy: 0.8322 - val_loss: 3.5849\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8806 - loss: 3.1225 - val_accuracy: 0.8680 - val_loss: 2.6425\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8670 - loss: 2.8710 - val_accuracy: 0.8568 - val_loss: 3.2137\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8735 - loss: 2.8550 - val_accuracy: 0.8345 - val_loss: 3.7707\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8827 - loss: 3.0737 - val_accuracy: 0.8814 - val_loss: 3.2398\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8746 - loss: 2.7979 - val_accuracy: 0.8792 - val_loss: 2.7143\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8664 - loss: 2.8522 - val_accuracy: 0.8881 - val_loss: 3.0778\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8815 - loss: 2.9589 - val_accuracy: 0.8859 - val_loss: 3.2591\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8729 - loss: 3.0671 - val_accuracy: 0.9060 - val_loss: 3.5904\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8899 - loss: 3.0579 - val_accuracy: 0.8501 - val_loss: 4.2186\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8843 - loss: 3.2662 - val_accuracy: 0.9016 - val_loss: 2.9998\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8613 - loss: 3.1561 - val_accuracy: 0.9038 - val_loss: 3.3555\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8683 - loss: 3.0366 - val_accuracy: 0.8747 - val_loss: 3.9676\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8663 - loss: 3.2233 - val_accuracy: 0.8926 - val_loss: 3.1590\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8862 - loss: 2.7216 - val_accuracy: 0.8837 - val_loss: 2.5617\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8797 - loss: 2.7192 - val_accuracy: 0.8680 - val_loss: 3.4717\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8737 - loss: 3.0591 - val_accuracy: 0.8680 - val_loss: 3.1521\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8721 - loss: 2.8864 - val_accuracy: 0.8523 - val_loss: 3.7483\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8721 - loss: 3.0682 - val_accuracy: 0.8591 - val_loss: 2.2931\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8940 - loss: 2.6158 - val_accuracy: 0.9083 - val_loss: 2.9915\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8851 - loss: 2.8036 - val_accuracy: 0.8971 - val_loss: 2.6217\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8890 - loss: 2.7414 - val_accuracy: 0.9083 - val_loss: 3.3323\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8733 - loss: 3.1570 - val_accuracy: 0.8300 - val_loss: 3.4771\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8678 - loss: 2.9430 - val_accuracy: 0.8904 - val_loss: 3.0656\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8817 - loss: 2.6647 - val_accuracy: 0.8747 - val_loss: 2.7836\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8851 - loss: 2.7468 - val_accuracy: 0.8971 - val_loss: 3.1868\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8842 - loss: 2.6410 - val_accuracy: 0.8568 - val_loss: 2.8221\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8919 - loss: 2.6376\n",
      "Test loss: 2.7829885482788086, Test accuracy: 0.8727598786354065\n",
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8737 - loss: 2.9813 - val_accuracy: 0.9016 - val_loss: 3.4089\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8680 - loss: 2.9475 - val_accuracy: 0.8949 - val_loss: 3.7471\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8824 - loss: 3.4215 - val_accuracy: 0.8926 - val_loss: 2.9364\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8741 - loss: 3.0024 - val_accuracy: 0.8747 - val_loss: 2.6852\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8943 - loss: 2.7627 - val_accuracy: 0.9150 - val_loss: 3.2830\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8793 - loss: 3.0375 - val_accuracy: 0.8412 - val_loss: 3.5522\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8725 - loss: 2.9034 - val_accuracy: 0.8747 - val_loss: 2.9711\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8853 - loss: 2.8078 - val_accuracy: 0.8546 - val_loss: 3.2356\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8793 - loss: 2.9645 - val_accuracy: 0.8188 - val_loss: 3.5871\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8693 - loss: 3.1046 - val_accuracy: 0.8837 - val_loss: 2.9019\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8951 - loss: 2.6283 - val_accuracy: 0.8971 - val_loss: 3.3230\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8778 - loss: 3.0222 - val_accuracy: 0.8904 - val_loss: 3.4426\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8964 - loss: 2.6675 - val_accuracy: 0.9150 - val_loss: 3.1747\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8913 - loss: 2.6818 - val_accuracy: 0.8993 - val_loss: 3.2382\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9084 - loss: 2.7303 - val_accuracy: 0.8613 - val_loss: 2.2723\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8539 - loss: 2.9247 - val_accuracy: 0.8456 - val_loss: 3.2724\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8752 - loss: 3.1295 - val_accuracy: 0.8702 - val_loss: 4.3097\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8675 - loss: 3.3559 - val_accuracy: 0.8725 - val_loss: 3.0721\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8719 - loss: 3.0158 - val_accuracy: 0.9060 - val_loss: 3.4186\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8849 - loss: 2.9656 - val_accuracy: 0.8658 - val_loss: 3.1183\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8548 - loss: 3.2830 - val_accuracy: 0.9038 - val_loss: 2.5244\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8864 - loss: 2.7226 - val_accuracy: 0.8792 - val_loss: 3.6598\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8884 - loss: 2.8534 - val_accuracy: 0.9038 - val_loss: 3.1330\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8665 - loss: 2.9326 - val_accuracy: 0.8859 - val_loss: 4.1542\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8835 - loss: 3.0230 - val_accuracy: 0.8837 - val_loss: 2.8600\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8810 - loss: 2.7591 - val_accuracy: 0.8546 - val_loss: 3.3001\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.8914 - loss: 2.8120 - val_accuracy: 0.9172 - val_loss: 3.4496\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9057 - loss: 2.5361 - val_accuracy: 0.9150 - val_loss: 3.1020\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8840 - loss: 2.6929 - val_accuracy: 0.8568 - val_loss: 4.1530\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8786 - loss: 2.9740 - val_accuracy: 0.8814 - val_loss: 2.5612\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8976 - loss: 2.5521 - val_accuracy: 0.8747 - val_loss: 3.0634\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8835 - loss: 2.8426 - val_accuracy: 0.8479 - val_loss: 2.8153\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8683 - loss: 2.7314 - val_accuracy: 0.9083 - val_loss: 2.5830\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8921 - loss: 2.4433 - val_accuracy: 0.8904 - val_loss: 2.9925\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8788 - loss: 3.0020 - val_accuracy: 0.8859 - val_loss: 2.6517\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8867 - loss: 2.6429 - val_accuracy: 0.8881 - val_loss: 2.7539\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8927 - loss: 2.6611 - val_accuracy: 0.9016 - val_loss: 2.5321\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8992 - loss: 2.9709 - val_accuracy: 0.9172 - val_loss: 2.8530\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8653 - loss: 2.9280 - val_accuracy: 0.8568 - val_loss: 2.8378\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8748 - loss: 2.5452 - val_accuracy: 0.8993 - val_loss: 2.7849\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8919 - loss: 2.6032 - val_accuracy: 0.8859 - val_loss: 2.4942\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8911 - loss: 2.5626 - val_accuracy: 0.8814 - val_loss: 2.5723\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.8766 - loss: 2.7476 - val_accuracy: 0.8837 - val_loss: 3.5690\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8814 - loss: 2.9656 - val_accuracy: 0.9150 - val_loss: 2.5015\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8846 - loss: 2.4894 - val_accuracy: 0.8792 - val_loss: 3.1850\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8816 - loss: 2.6973 - val_accuracy: 0.8904 - val_loss: 3.5825\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8743 - loss: 2.7808 - val_accuracy: 0.9016 - val_loss: 2.5475\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8735 - loss: 2.7779 - val_accuracy: 0.9016 - val_loss: 2.6347\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8945 - loss: 2.4732 - val_accuracy: 0.8971 - val_loss: 3.2679\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8789 - loss: 2.9177 - val_accuracy: 0.9060 - val_loss: 3.2600\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 3.1324\n",
      "Test loss: 3.320650815963745, Test accuracy: 0.9032257795333862\n",
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8697 - loss: 3.0278 - val_accuracy: 0.8859 - val_loss: 2.7824\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8947 - loss: 2.6308 - val_accuracy: 0.9060 - val_loss: 2.7343\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8785 - loss: 2.8583 - val_accuracy: 0.8859 - val_loss: 2.1326\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8772 - loss: 2.4061 - val_accuracy: 0.8725 - val_loss: 4.0744\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8725 - loss: 2.9489 - val_accuracy: 0.8434 - val_loss: 2.2520\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8870 - loss: 2.3872 - val_accuracy: 0.8837 - val_loss: 2.6568\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8754 - loss: 2.4984 - val_accuracy: 0.8166 - val_loss: 2.8106\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8785 - loss: 3.0093 - val_accuracy: 0.8837 - val_loss: 2.8645\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8776 - loss: 2.6854 - val_accuracy: 0.8658 - val_loss: 2.7613\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8796 - loss: 2.5664 - val_accuracy: 0.8792 - val_loss: 2.5148\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8748 - loss: 2.8192 - val_accuracy: 0.9128 - val_loss: 2.8116\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8626 - loss: 3.1748 - val_accuracy: 0.8456 - val_loss: 2.3336\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8815 - loss: 2.4889 - val_accuracy: 0.8770 - val_loss: 3.1006\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8839 - loss: 2.7805 - val_accuracy: 0.8859 - val_loss: 2.8833\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8972 - loss: 2.5106 - val_accuracy: 0.8881 - val_loss: 3.2712\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8926 - loss: 2.6381 - val_accuracy: 0.8814 - val_loss: 2.8036\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8883 - loss: 2.5811 - val_accuracy: 0.9060 - val_loss: 3.0111\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8883 - loss: 2.7658 - val_accuracy: 0.9083 - val_loss: 3.0585\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8767 - loss: 3.2265 - val_accuracy: 0.8546 - val_loss: 4.3832\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8956 - loss: 3.3488 - val_accuracy: 0.8434 - val_loss: 4.0528\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8938 - loss: 2.7755 - val_accuracy: 0.8949 - val_loss: 2.4814\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8714 - loss: 2.4087 - val_accuracy: 0.9128 - val_loss: 3.5151\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8864 - loss: 2.6772 - val_accuracy: 0.9016 - val_loss: 2.3363\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8876 - loss: 2.4167 - val_accuracy: 0.9105 - val_loss: 2.5976\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.8852 - loss: 2.8552 - val_accuracy: 0.9195 - val_loss: 2.8006\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8935 - loss: 2.4939 - val_accuracy: 0.8904 - val_loss: 3.0886\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8882 - loss: 2.7233 - val_accuracy: 0.9016 - val_loss: 2.8058\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8810 - loss: 2.8437 - val_accuracy: 0.8971 - val_loss: 3.1700\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8701 - loss: 2.9465 - val_accuracy: 0.8949 - val_loss: 3.6089\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8780 - loss: 3.0038 - val_accuracy: 0.9083 - val_loss: 3.0108\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - accuracy: 0.8749 - loss: 2.5427 - val_accuracy: 0.9150 - val_loss: 2.5067\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8945 - loss: 2.5485 - val_accuracy: 0.9105 - val_loss: 2.4581\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8924 - loss: 2.4666 - val_accuracy: 0.9150 - val_loss: 2.8124\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8881 - loss: 2.5423 - val_accuracy: 0.9060 - val_loss: 2.5844\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8946 - loss: 2.3318 - val_accuracy: 0.8971 - val_loss: 2.8676\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8849 - loss: 2.7008 - val_accuracy: 0.9016 - val_loss: 2.3367\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 142ms/step - accuracy: 0.8997 - loss: 2.3523 - val_accuracy: 0.9239 - val_loss: 2.8157\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8979 - loss: 2.5599 - val_accuracy: 0.8546 - val_loss: 3.1176\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8771 - loss: 2.6855 - val_accuracy: 0.8881 - val_loss: 2.9533\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8766 - loss: 2.8631 - val_accuracy: 0.8859 - val_loss: 3.1391\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8869 - loss: 2.5762 - val_accuracy: 0.8971 - val_loss: 2.7279\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8842 - loss: 2.4190 - val_accuracy: 0.8993 - val_loss: 3.2384\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8861 - loss: 2.5828 - val_accuracy: 0.8546 - val_loss: 3.2977\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8772 - loss: 2.7937 - val_accuracy: 0.9217 - val_loss: 2.6524\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8791 - loss: 2.7041 - val_accuracy: 0.9083 - val_loss: 3.0334\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9072 - loss: 2.3166 - val_accuracy: 0.8814 - val_loss: 2.2460\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9025 - loss: 2.3490 - val_accuracy: 0.8814 - val_loss: 2.7570\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8657 - loss: 3.1066 - val_accuracy: 0.8792 - val_loss: 3.1343\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8865 - loss: 2.7252 - val_accuracy: 0.9060 - val_loss: 2.2517\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8909 - loss: 2.6203 - val_accuracy: 0.8881 - val_loss: 2.8490\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9006 - loss: 2.6271\n",
      "Test loss: 2.788778305053711, Test accuracy: 0.8906810283660889\n",
      "Epoch 1/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8922 - loss: 2.7496 - val_accuracy: 0.8837 - val_loss: 2.7059\n",
      "Epoch 2/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8800 - loss: 2.4929 - val_accuracy: 0.9038 - val_loss: 2.2691\n",
      "Epoch 3/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8961 - loss: 2.4085 - val_accuracy: 0.8322 - val_loss: 3.2329\n",
      "Epoch 4/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8733 - loss: 2.9071 - val_accuracy: 0.8859 - val_loss: 2.6201\n",
      "Epoch 5/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8959 - loss: 2.5710 - val_accuracy: 0.9060 - val_loss: 2.3314\n",
      "Epoch 6/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8912 - loss: 2.5894 - val_accuracy: 0.8725 - val_loss: 3.0110\n",
      "Epoch 7/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8811 - loss: 2.7952 - val_accuracy: 0.8479 - val_loss: 3.0502\n",
      "Epoch 8/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8795 - loss: 3.2395 - val_accuracy: 0.9016 - val_loss: 2.5813\n",
      "Epoch 9/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8883 - loss: 2.6361 - val_accuracy: 0.8971 - val_loss: 2.5384\n",
      "Epoch 10/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8915 - loss: 2.3920 - val_accuracy: 0.9128 - val_loss: 2.9988\n",
      "Epoch 11/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8738 - loss: 2.6474 - val_accuracy: 0.9060 - val_loss: 2.9895\n",
      "Epoch 12/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9037 - loss: 2.3484 - val_accuracy: 0.9128 - val_loss: 3.7379\n",
      "Epoch 13/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9010 - loss: 2.5364 - val_accuracy: 0.9105 - val_loss: 1.9070\n",
      "Epoch 14/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8846 - loss: 2.2880 - val_accuracy: 0.9083 - val_loss: 2.5027\n",
      "Epoch 15/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8987 - loss: 2.3491 - val_accuracy: 0.9150 - val_loss: 3.0208\n",
      "Epoch 16/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8876 - loss: 2.7247 - val_accuracy: 0.8747 - val_loss: 2.5862\n",
      "Epoch 17/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8749 - loss: 2.6856 - val_accuracy: 0.9060 - val_loss: 3.2220\n",
      "Epoch 18/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8933 - loss: 2.5045 - val_accuracy: 0.8837 - val_loss: 2.0766\n",
      "Epoch 19/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8868 - loss: 2.5065 - val_accuracy: 0.8770 - val_loss: 3.3074\n",
      "Epoch 20/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8978 - loss: 2.7150 - val_accuracy: 0.8501 - val_loss: 3.9319\n",
      "Epoch 21/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8893 - loss: 2.8457 - val_accuracy: 0.9038 - val_loss: 3.1100\n",
      "Epoch 22/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8976 - loss: 2.5992 - val_accuracy: 0.9016 - val_loss: 3.3357\n",
      "Epoch 23/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.8855 - loss: 2.7636 - val_accuracy: 0.8993 - val_loss: 2.6875\n",
      "Epoch 24/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.8815 - loss: 2.8074 - val_accuracy: 0.8702 - val_loss: 3.0549\n",
      "Epoch 25/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8762 - loss: 2.8655 - val_accuracy: 0.9060 - val_loss: 2.5490\n",
      "Epoch 26/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8758 - loss: 2.6394 - val_accuracy: 0.9060 - val_loss: 2.5812\n",
      "Epoch 27/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8823 - loss: 2.5874 - val_accuracy: 0.9105 - val_loss: 2.4956\n",
      "Epoch 28/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8949 - loss: 2.2597 - val_accuracy: 0.8770 - val_loss: 2.3891\n",
      "Epoch 29/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8995 - loss: 2.3441 - val_accuracy: 0.8993 - val_loss: 2.7943\n",
      "Epoch 30/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8894 - loss: 2.4072 - val_accuracy: 0.8881 - val_loss: 2.2276\n",
      "Epoch 31/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8889 - loss: 2.4797 - val_accuracy: 0.8949 - val_loss: 2.4752\n",
      "Epoch 32/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8846 - loss: 2.8005 - val_accuracy: 0.8770 - val_loss: 3.4055\n",
      "Epoch 33/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8902 - loss: 2.8176 - val_accuracy: 0.8792 - val_loss: 3.7014\n",
      "Epoch 34/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8931 - loss: 2.8199 - val_accuracy: 0.8725 - val_loss: 3.1501\n",
      "Epoch 35/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8794 - loss: 2.6266 - val_accuracy: 0.8993 - val_loss: 2.9824\n",
      "Epoch 36/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8826 - loss: 2.5057 - val_accuracy: 0.8971 - val_loss: 3.7805\n",
      "Epoch 37/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8779 - loss: 2.8920 - val_accuracy: 0.8926 - val_loss: 3.7682\n",
      "Epoch 38/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8912 - loss: 2.8459 - val_accuracy: 0.9060 - val_loss: 2.2710\n",
      "Epoch 39/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8747 - loss: 2.6376 - val_accuracy: 0.9195 - val_loss: 2.4568\n",
      "Epoch 40/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.8814 - loss: 2.3490 - val_accuracy: 0.8993 - val_loss: 2.5064\n",
      "Epoch 41/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8810 - loss: 2.4801 - val_accuracy: 0.9172 - val_loss: 3.0541\n",
      "Epoch 42/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9011 - loss: 2.3812 - val_accuracy: 0.8635 - val_loss: 2.7838\n",
      "Epoch 43/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8927 - loss: 2.6260 - val_accuracy: 0.9083 - val_loss: 2.4949\n",
      "Epoch 44/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.8851 - loss: 2.4850 - val_accuracy: 0.8971 - val_loss: 2.5968\n",
      "Epoch 45/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8922 - loss: 2.4586 - val_accuracy: 0.8792 - val_loss: 2.3001\n",
      "Epoch 46/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8804 - loss: 2.4495 - val_accuracy: 0.9016 - val_loss: 2.1078\n",
      "Epoch 47/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8991 - loss: 2.1759 - val_accuracy: 0.8949 - val_loss: 3.0420\n",
      "Epoch 48/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9019 - loss: 2.5561 - val_accuracy: 0.8568 - val_loss: 2.8671\n",
      "Epoch 49/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8926 - loss: 2.8474 - val_accuracy: 0.8859 - val_loss: 2.9132\n",
      "Epoch 50/50\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8892 - loss: 2.8020 - val_accuracy: 0.9128 - val_loss: 2.4987\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9335 - loss: 2.3426\n",
      "Test loss: 2.5210683345794678, Test accuracy: 0.9157705903053284\n",
      "[(3.130251169204712, 0.8494623899459839), (2.7829885482788086, 0.8727598786354065), (3.320650815963745, 0.9032257795333862), (2.788778305053711, 0.8906810283660889), (2.5210683345794678, 0.9157705903053284)]\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    hp_output1 = hp.Int('output_dim_prev_event', min_value=24, max_value=44, step=2)\n",
    "    hp_output2 = hp.Int('output_dim_prev_prev_event', min_value=24, max_value=44, step=2)\n",
    "    hp_output3 = hp.Int('output_dim_session_id', min_value=24, max_value=44, step=2)\n",
    "    hp_output4 = hp.Int('output_dim_device_id', min_value=24, max_value=44, step=2)\n",
    "    hp_output5 = hp.Int('output_dim_output', min_value=24, max_value=44, step=2)\n",
    "\n",
    "    embedding_input_prev_event = tf.keras.layers.Input(shape=(1,), dtype='int32') \n",
    "    embedding_layer_prev_event = tf.keras.layers.Embedding(input_dim=X_train_prev_event_input_dim, output_dim=hp_output1)(embedding_input_prev_event)\n",
    "    flattened_prev_event = tf.keras.layers.Flatten()(embedding_layer_prev_event)\n",
    "\n",
    "    embedding_input_prev_prev_event = tf.keras.layers.Input(shape=(1,), dtype='int32') \n",
    "    embedding_layer_prev_prev_event = tf.keras.layers.Embedding(input_dim=X_train_prev_prev_event_input_dim, output_dim=hp_output2)(embedding_input_prev_prev_event)\n",
    "    flattened_prev_prev_event = tf.keras.layers.Flatten()(embedding_layer_prev_prev_event)\n",
    "    \n",
    "    embedding_input_session_id = tf.keras.layers.Input(shape=(1,), dtype='int32') \n",
    "    embedding_layer_session_id = tf.keras.layers.Embedding(input_dim=76, output_dim=hp_output3)(embedding_input_session_id)\n",
    "    flattened_session_id = tf.keras.layers.Flatten()(embedding_layer_session_id)\n",
    "\n",
    "    embedding_input_device_id = tf.keras.layers.Input(shape=(1,), dtype='int32') \n",
    "    embedding_layer_device_id = tf.keras.layers.Embedding(input_dim=41, output_dim=hp_output4)(embedding_input_device_id)\n",
    "    flattened_device_id = tf.keras.layers.Flatten()(embedding_layer_device_id)\n",
    "\n",
    "    concatenated_embeddings = tf.keras.layers.Concatenate()([flattened_prev_event, flattened_prev_prev_event, flattened_session_id, flattened_device_id])\n",
    "    #concatenated_embeddings = tf.keras.layers.Concatenate()([flattened_prev_event, flattened_session_id, flattened_device_id])\n",
    "    #concatenated_embeddings = tf.keras.layers.Concatenate()([flattened_session_id, flattened_device_id])\n",
    "\n",
    "    flattened_input = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "    flattened = tf.keras.layers.Flatten()(flattened_input)\n",
    "    concatenated = tf.keras.layers.Concatenate()([concatenated_embeddings, flattened])\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=16, max_value=1024, step=32)\n",
    "    hp_layers = hp.Int('layers', min_value=2, max_value=5, step=1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam'])\n",
    "    hp_regularization = hp.Choice('regularization', values=['l1', 'l2', 'l1_l2'])\n",
    "    hp_lambda = hp.Float('lambda', min_value=0.5, max_value=1.0, step=0.01)\n",
    "    \n",
    "    for i in range(hp_layers):\n",
    "        if hp_regularization == 'l1':\n",
    "            regularizer = tf.keras.regularizers.l1(hp_lambda)\n",
    "        elif hp_regularization == 'l2':\n",
    "            regularizer = tf.keras.regularizers.l2(hp_lambda)\n",
    "        else: # l1_l2\n",
    "            regularizer = tf.keras.regularizers.l1_l2(l1=hp_lambda, l2=hp_lambda)\n",
    "        \n",
    "        concatenated = tf.keras.layers.Dense(units=hp_units, activation='relu', kernel_regularizer=regularizer)(concatenated)\n",
    "        concatenated = tf.keras.layers.BatchNormalization()(concatenated)\n",
    "        concatenated = tf.keras.layers.Dropout(0.3)(concatenated)    \n",
    "     \n",
    "    \n",
    "    \n",
    "    output_embedding_input = tf.keras.layers.Input(shape=(1,), dtype='int32')\n",
    "    output_embedding_layer = tf.keras.layers.Embedding(input_dim=unique_classifications, output_dim=hp_output5)(output_embedding_input)\n",
    "    flattened_output_embedding = tf.keras.layers.Flatten()(output_embedding_layer)\n",
    "    \n",
    "    final_concatenated = tf.keras.layers.Concatenate()([concatenated, flattened_output_embedding])\n",
    "    \n",
    "    output = tf.keras.layers.Dense(unique_classifications, activation='softmax')(final_concatenated)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[embedding_input_prev_event, embedding_input_prev_prev_event, embedding_input_session_id, embedding_input_device_id, flattened_input, output_embedding_input], outputs=output)\n",
    "    #model = tf.keras.models.Model(inputs=[embedding_input_prev_event, embedding_input_session_id, embedding_input_device_id, flattened_input, output_embedding_input], outputs=output)\n",
    "    #model = tf.keras.models.Model(inputs=[embedding_input_session_id, embedding_input_device_id, flattened_input, output_embedding_input], outputs=output)\n",
    "        \n",
    "    optimizer = hp_optimizer\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "best_performance = 0\n",
    "best_model_path = r'trained_models\\best_model\\best_model.keras'\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "performance_metrics = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    X_train_prev_event_fold, X_val_prev_event_fold = X_train_prev_event[train_index], X_train_prev_event[val_index]\n",
    "    X_train_prev_prev_event_fold, X_val_prev_prev_event_fold = X_train_prev_prev_event[train_index], X_train_prev_prev_event[val_index]\n",
    "    X_train_session_fold, X_val_session_fold = X_train_session_id[train_index], X_train_session_id[val_index]\n",
    "    X_train_device_fold, X_val_device_fold = X_train_device_id[train_index], X_train_device_id[val_index]\n",
    "    X_train_output_fold, X_val_output_fold = X_train_content_id[train_index], X_train_content_id[val_index]\n",
    "    \n",
    "    X_train_fold_inputs = [X_train_prev_event_fold, X_train_prev_prev_event_fold, X_train_session_fold, X_train_device_fold, X_train_fold, X_train_output_fold]\n",
    "    X_val_fold_inputs = [X_val_prev_event_fold, X_val_prev_prev_event_fold, X_val_session_fold, X_val_device_fold, X_val_fold, X_val_output_fold]\n",
    "\n",
    "    #X_train_fold_inputs = [X_train_prev_event_fold, X_train_session_fold, X_train_device_fold, X_train_fold, X_train_output_fold]\n",
    "    #X_val_fold_inputs = [X_val_prev_event_fold, X_val_session_fold, X_val_device_fold, X_val_fold, X_val_output_fold]\n",
    "\n",
    "    #X_train_fold_inputs = [X_train_session_fold, X_train_device_fold, X_train_fold, X_train_output_fold]\n",
    "    #X_val_fold_inputs = [X_val_session_fold, X_val_device_fold, X_val_fold, X_val_output_fold]\n",
    "\n",
    "\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    tuner = kt.BayesianOptimization(\n",
    "        model_builder,\n",
    "        objective='val_accuracy', \n",
    "        max_trials=25,\n",
    "        executions_per_trial=3,\n",
    "        directory='trained_models',\n",
    "        project_name='DI_9' \n",
    "    )\n",
    "\n",
    "    tuner.search(X_train_fold_inputs, y_train_fold, epochs=50, validation_data=(X_val_fold_inputs, y_val_fold))\n",
    "    \n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    eval_result = best_model.evaluate(X_val_fold_inputs, y_val_fold)\n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "\n",
    "    performance_metrics.append(eval_result[1])\n",
    "\n",
    "    if eval_result[1] > best_performance:\n",
    "        best_performance = eval_result[1]\n",
    "        best_model.save(best_model_path)\n",
    "\n",
    "X_train_inputs = [X_train_prev_event, X_train_prev_prev_event, X_train_session_id, X_train_device_id, X_train,  X_train_content_id]\n",
    "X_test_inputs = [X_test_prev_event, X_test_prev_prev_event, X_test_session_id, X_test_device_id, X_test, X_test_content_id]\n",
    "\n",
    "#X_train_inputs = [X_train_prev_event, X_train_session_id, X_train_device_id, X_train,  X_train_content_id]\n",
    "#X_test_inputs = [X_test_prev_event, X_test_session_id, X_test_device_id, X_test, X_test_content_id]\n",
    "\n",
    "#X_train_inputs = [X_train_session_id, X_train_device_id, X_train,  X_train_content_id]\n",
    "#X_test_inputs = [X_test_session_id, X_test_device_id, X_test, X_test_content_id]\n",
    "\n",
    "average_performance = np.mean(performance_metrics)\n",
    "print(f\"Average validation accuracy across all folds: {average_performance}\")\n",
    "\n",
    "best_model = keras.models.load_model(best_model_path)\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "history_test = []\n",
    "for i in range(5):\n",
    "    history = best_model.fit(X_train_inputs, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    test_loss, test_accuracy = best_model.evaluate(X_test_inputs, y_test)\n",
    "    history_test.append((test_loss, test_accuracy))\n",
    "    print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "print(history_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(loc='lower right')\n",
    "\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"val_accuracy: \", history.history['val_accuracy'])\n",
    "print(\"accuracy: \", history.history['accuracy'])\n",
    "print(\"val_loss: \", history.history['val_loss'])\n",
    "print(\"loss: \", history.history['loss'])\n",
    "\n",
    "plot_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in best_hps.values.items():\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "\n",
    "tuner.results_summary(num_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
